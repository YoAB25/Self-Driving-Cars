{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification and the CIFAR-10 dataset\n",
    "\n",
    "We will use a standardized dataset called CIFAR-10. CIFAR-10 consists of 60000 images. There are 10 different categories and 6000 images per category. Each image has a size of only 32 by 32 pixels. The small size makes it sometimes difficult for us humans to recognize the correct category, but it simplifies things for our computer model and reduces the computational load required to analyze the images.*\n",
    "*, by \\url{https://www.wolfib.com/Image-Recognition-Intro-Part-1/#prerequisites}\n",
    "\n",
    "The CIFAR-10 contains 10 classes : plane, car, bird, cat, deer, frog, horse, ship, truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`labels.shape.rank` must equal `logits.shape.rank - 1`. Received: labels.shape=(None, 10) of rank 2 and logits.shape=(None, 10) of rank 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W1sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m logits \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmatmul(images_placeholder,weights) \u001b[39m+\u001b[39m biases\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W1sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# Define the loss function calculated based on the Cross-Entropy -> well there is an activation before to turn into probabilities\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# NOTE: Loss is the difference between the predition and the actual result(the label in this case)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W1sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49msparse_softmax_cross_entropy_with_logits(logits,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W1sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m   labels_placeholder))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Define the training operation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W1sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m train_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mGradientDescentOptimizer(learning_rate)\u001b[39m.\u001b[39mminimize(loss)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/nn_ops.py:4354\u001b[0m, in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m   4349\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   4350\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`logits` cannot be a scalar. Received logits=\u001b[39m\u001b[39m{\u001b[39;00mlogits\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4351\u001b[0m \u001b[39mif\u001b[39;00m logits\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mndims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m (\n\u001b[1;32m   4352\u001b[0m     labels_static_shape\u001b[39m.\u001b[39mndims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m   4353\u001b[0m     labels_static_shape\u001b[39m.\u001b[39mndims \u001b[39m!=\u001b[39m logits\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mndims \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m-> 4354\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   4355\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`labels.shape.rank` must equal `logits.shape.rank - 1`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4356\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived: labels.shape=\u001b[39m\u001b[39m{\u001b[39;00mlabels_static_shape\u001b[39m}\u001b[39;00m\u001b[39m of rank \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4357\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels_static_shape\u001b[39m.\u001b[39mrank\u001b[39m}\u001b[39;00m\u001b[39m and logits.shape=\u001b[39m\u001b[39m{\u001b[39;00mlogits\u001b[39m.\u001b[39mget_shape()\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4358\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof rank \u001b[39m\u001b[39m{\u001b[39;00mlogits\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mrank\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4359\u001b[0m \u001b[39mif\u001b[39;00m (static_shapes_fully_defined \u001b[39mand\u001b[39;00m\n\u001b[1;32m   4360\u001b[0m     labels_static_shape \u001b[39m!=\u001b[39m logits\u001b[39m.\u001b[39mget_shape()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]):\n\u001b[1;32m   4361\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   4362\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`labels.shape` must equal `logits.shape` except for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4363\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthe last dimension. Received: labels.shape=\u001b[39m\u001b[39m{\u001b[39;00mlabels_static_shape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4364\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand logits.shape=\u001b[39m\u001b[39m{\u001b[39;00mlogits\u001b[39m.\u001b[39mget_shape()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: `labels.shape.rank` must equal `logits.shape.rank - 1`. Received: labels.shape=(None, 10) of rank 2 and logits.shape=(None, 10) of rank 2"
     ]
    }
   ],
   "source": [
    "# sotmax.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import time\n",
    "import data_helpers\n",
    "\n",
    "beginTime = time.time()\n",
    "\n",
    "# Learning parameters\n",
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "max_steps = 1000\n",
    "\n",
    "# Prepare data : Load the CIFAR-10 dataset\n",
    "data_sets = data_helpers.load_data()\n",
    "\n",
    "# NOTE : The dataset contains actually 60000 images but we are spliting them into 2 parts\n",
    "# - A training set \n",
    "# - A testing set (for validating our model)\n",
    "\n",
    "# According to the same source code used (link Github Below) load_data() fct return the following:\n",
    "# images_train -> Training set of array 50000*image = 50000*(32.pix*32.pix*3.color_channels(RGB))\n",
    "# labels_train -> Labels for training set (we're doing supervized learning so all our features are labelized (from 0 to 9 for each class))\n",
    "# images_test -> 10000 * (3072)\n",
    "# labels_test -> 10000 images (features) labelized\n",
    "# classes -> probably a dictionary that associate a for each key(class number) its name as value \n",
    "# \n",
    "\n",
    "# Enable TensorFlow v.1.x compatibility (version installed latest v.2.x)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Define placeholders\n",
    "images_placeholder = tf.compat.v1.placeholder(tf.float32, shape=[None, 3072])\n",
    "labels_placeholder = tf.compat.v1.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "# Define variables\n",
    "weights = tf.Variable(tf.zeros([3072,10]))\n",
    "biases = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# NOTE : An image is represented by a linear array of 3072 values. \n",
    "# Each value is multiplied by a weight parameter and the results are summed up to arrive at a single result - the image's score for a specific class\n",
    "# Well scores are also called logits that will be converted into probabilities later.\n",
    "\n",
    "'''\n",
    "Image = [0.5 0.8 0.1 (3072...) 0.2 0.3]*(3072*10 matrix) + (3072 biases(rows NULL in our case)) -> Result(10 scores)\n",
    "'''\n",
    "\n",
    "# Begin feedforward : Apply the multiplication and getting logits\n",
    "logits = tf.matmul(images_placeholder,weights) + biases\n",
    "\n",
    "# Define the loss function calculated based on the Cross-Entropy -> well there is an activation before to turn into probabilities\n",
    "# NOTE: Loss is the difference between the predition and the actual result(the label in this case)\n",
    "loss = tf.compat.v1.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits,\n",
    "  labels_placeholder))\n",
    "\n",
    "# Define the training operation\n",
    "train_step = tf.compat.v1.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Operation comparing prediction with true label\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), labels_placeholder)\n",
    "\n",
    "# Operation calculating the accuracy of our predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run the TensorFlow graph\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Initialize all Tensor variables\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "with tf.compat.v1.Session as sess:\n",
    "    sess.run(init)\n",
    "    # Repeat for each epochs\n",
    "    for i in range(max_steps):\n",
    "        # Generate input data batch\n",
    "        indices = np.random.choice(data_sets['images_train'].shape[0], batch_size)\n",
    "        images_batch = data_sets['images_train'][indices]\n",
    "        labels_batch = data_sets['labels_train'][indices]\n",
    "\n",
    "        # Periodically print out the model's current accuracy\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={\n",
    "                images_placeholder: images_batch, labels_placeholder: labels_batch})\n",
    "            print('Step {:5d}: training accuracy {:g}'.format(i, train_accuracy))\n",
    "        # Perform a single training step\n",
    "        sess.run(train_step, feed_dict={images_placeholder: images_batch,\n",
    "        labels_placeholder: labels_batch})\n",
    "    \n",
    "    # After finishing the training, evaluate on the test set\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={images_placeholder: data_sets['images_test'],\n",
    "    labels_placeholder: data_sets['labels_test']})\n",
    "    print('Test accuracy {:g}'.format(test_accuracy))\n",
    "\n",
    "endTime = time.time()\n",
    "print('Total time: {:5.2f}s'.format(endTime - beginTime))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:57:26.716407: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-24 15:57:56.621192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m data_sets \u001b[39m=\u001b[39m data_helpers\u001b[39m.\u001b[39mload_data()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Prepare the TensorFlow graph\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# (We're only defining the graph here, no actual calculations taking place)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Define input placeholders\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m images_placeholder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mplaceholder(tf\u001b[39m.\u001b[39mfloat32, shape\u001b[39m=\u001b[39m[\u001b[39mNone\u001b[39;00m, \u001b[39m3072\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m labels_placeholder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mplaceholder(tf\u001b[39m.\u001b[39mint64, shape\u001b[39m=\u001b[39m[\u001b[39mNone\u001b[39;00m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/youssefab/All_Projects/Self-Driving-Cars/MOD1-Computer_Vision_Deep_Learning/Labs/T1_M3_Other_Labs/Simple_Image_Recognition/lab_SIR.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Define variables (these are the values we want to optimize)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import data_helpers\n",
    "\n",
    "beginTime = time.time()\n",
    "\n",
    "# Parameter definitions\n",
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "max_steps = 1000\n",
    "\n",
    "# Uncommenting this line removes randomness\n",
    "# You'll get exactly the same result on each run\n",
    "# np.random.seed(1)\n",
    "\n",
    "# Prepare data\n",
    "data_sets = data_helpers.load_data()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Prepare the TensorFlow graph\n",
    "# (We're only defining the graph here, no actual calculations taking place)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define input placeholders\n",
    "images_placeholder = tf.placeholder(tf.float32, shape=[None, 3072])\n",
    "labels_placeholder = tf.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "# Define variables (these are the values we want to optimize)\n",
    "weights = tf.Variable(tf.zeros([3072, 10]))\n",
    "biases = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Define the classifier's result\n",
    "logits = tf.matmul(images_placeholder, weights) + biases\n",
    "\n",
    "# Define the loss function\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "  labels=labels_placeholder))\n",
    "\n",
    "# Define the training operation\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Operation comparing prediction with true label\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), labels_placeholder)\n",
    "\n",
    "# Operation calculating the accuracy of our predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run the TensorFlow graph\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Initialize variables\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "\n",
    "  # Repeat max_steps times\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # Generate input data batch\n",
    "    indices = np.random.choice(data_sets['images_train'].shape[0], batch_size)\n",
    "    images_batch = data_sets['images_train'][indices]\n",
    "    labels_batch = data_sets['labels_train'][indices]\n",
    "\n",
    "    # Periodically print out the model's current accuracy\n",
    "    if i % 100 == 0:\n",
    "      train_accuracy = sess.run(accuracy, feed_dict={\n",
    "        images_placeholder: images_batch, labels_placeholder: labels_batch})\n",
    "      print('Step {:5d}: training accuracy {:g}'.format(i, train_accuracy))\n",
    "\n",
    "    # Perform a single training step\n",
    "    sess.run(train_step, feed_dict={images_placeholder: images_batch,\n",
    "      labels_placeholder: labels_batch})\n",
    "\n",
    "  # After finishing the training, evaluate on the test set\n",
    "  test_accuracy = sess.run(accuracy, feed_dict={\n",
    "    images_placeholder: data_sets['images_test'],\n",
    "    labels_placeholder: data_sets['labels_test']})\n",
    "  print('Test accuracy {:g}'.format(test_accuracy))\n",
    "\n",
    "endTime = time.time()\n",
    "print('Total time: {:5.2f}s'.format(endTime - beginTime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
